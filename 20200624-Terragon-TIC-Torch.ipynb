{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terragon.de Image Classifier (TIC-Torch)\n",
    "### based on a PyTorch Convolutional Neural Network\n",
    "\n",
    "## Why TIC-Torch?\n",
    "\n",
    "The TIC-Torch application offers a convenient, fast and effective workflow to create, train and deploy individual and versatile image classifiers.\n",
    "\n",
    "## What's the workflow?\n",
    "\n",
    "1. Collect many jpg files of the objects you want to classify and arrange them in the \"raw\" directory. Create one subfolder for each object you want to classify and put the images inside. Example:\n",
    "    - raw/dogs\n",
    "    - raw/cats\n",
    "    - raw/humans\n",
    "3. Run TIC-Torch to resize and vary the images and to train the Neural Network.\n",
    "4. Run TIC-Torch to classify a new jpg.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import OS and Image manipulation libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Libraries\n",
    "\n",
    "import os, sys\n",
    "from distutils.dir_util import copy_tree\n",
    "from PIL import Image, ImageEnhance\n",
    "import PIL.ImageOps\n",
    "import random\n",
    "\n",
    "# PyTorch Libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Other Libraries we'll use\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_raw = \"raw/\"\n",
    "path_images_train = \"train/\"\n",
    "\n",
    "resize_x = 128\n",
    "resize_y = 128\n",
    "\n",
    "batch_size = 50\n",
    "shuffle = True\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list subdirs in raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_raw_subdirs = os.listdir(path_images_raw)\n",
    "print(\"raw/ subdirs: \",path_images_raw_subdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy all images from raw/ to train/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImagesCopy(path_images_raw,path_images_train):\n",
    "    copy_tree(path_images_raw, path_images_train)\n",
    "    path_images_train_subdirs = os.listdir(path_images_train)\n",
    "    print(\"copy from raw to train/ folder. done.\")\n",
    "    print(\"train subdirs: \",path_images_train_subdirs)\n",
    "ImagesCopy(path_images_raw,path_images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resize all images in train/ to neural network size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImagesResize():\n",
    "    for subdir, dirs, files in os.walk(path_images_train):\n",
    "        for file in files:\n",
    "            path_image = os.path.join(subdir, file)\n",
    "            if os.path.isfile(path_image):\n",
    "                im = Image.open(path_image)\n",
    "                f, e = os.path.splitext(path_image)\n",
    "                imResize = im.resize((resize_x,resize_y), Image.Resampling.LANCZOS)\n",
    "                imResize.save(f + '_resized.jpg', 'JPEG', quality=90)\n",
    "                os.remove(path_image)\n",
    "    print(\"resized all images in folder train/\")\n",
    "ImagesResize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create variations of all images in train/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageVariations():\n",
    "    for subdir, dirs, files in os.walk(path_images_train):\n",
    "        for file in files:\n",
    "            path_image = os.path.join(subdir, file)\n",
    "            if os.path.isfile(path_image):\n",
    "                im = Image.open(path_image)\n",
    "                \n",
    "                f, e = os.path.splitext(path_image)\n",
    "                enhancer = ImageEnhance.Brightness(im)\n",
    "                imLighter = enhancer.enhance(1.8)\n",
    "                imLighter.save(f + '_lighter.jpg', 'JPEG', quality=90)\n",
    "                imDarker = enhancer.enhance(0.5)\n",
    "                imDarker.save(f + '_darker.jpg', 'JPEG', quality=90)\n",
    "                imInverted = PIL.ImageOps.invert(im)\n",
    "                imInverted.save(f + '_inverted.jpg', 'JPEG', quality=90)\n",
    "                randomRotate = random.randrange(-45,45)\n",
    "                imRotated = im.rotate(randomRotate)\n",
    "                imRotated.save(f + '_rotated.jpg', 'JPEG', quality=90)\n",
    "                imMirror = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                imMirror.save(f + '_mirrored.jpg', 'JPEG', quality=90)\n",
    "                imGrey = im.convert('L')\n",
    "                imGrey.save(f + '_greyscale.jpg', 'JPEG', quality=90)\n",
    "    print(\"added a mirror and greyscale images for all images in folder train/\")\n",
    "ImageVariations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer all Images to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ingest data using training and test loaders\n",
    "# Now load the images from the train folder\n",
    "\n",
    "def load_dataset(path_images_train):\n",
    "    # Load all of the images\n",
    "    transformation = transforms.Compose([\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=path_images_train,\n",
    "        transform=transformation\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(path_images_train)\n",
    "classes.sort()\n",
    "classes_amount = len(classes)\n",
    "print(len(classes), 'classes:')\n",
    "print(classes)\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(path_images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, num_classes=classes_amount):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Our images are RGB, so input channels = 3. wW'll apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We'll apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 12 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A third convolutional layer takes 12 inputs and generates 24 outputs\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # So our feature tensors are now 32 x 32, and we've generated 24 of them\n",
    "        # We need to flatten these to map them to  the probability for each class\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use a relu activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        # Use a relu activation function after layer 1 (convolution 2 and drop)\n",
    "        \n",
    "        # Use a relu activation function after layer 3 (convolution 3)\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        \n",
    "        # Drop some features after the 3rd convolution to prevent overfitting\n",
    "        x = F.relu(self.drop(self.conv3(x)))\n",
    "        # Only drop the features if this is a training pass\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        x = self.fc(x)\n",
    "        # Return class probabilities via a softmax function \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "print(\"CNN model class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print metrics for every 10 batches so we see some progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    # return average loss for the epoch\n",
    "    return train_loss / len(train_loader.dataset)\n",
    "            \n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            # calculate the loss and successful predictions for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1] \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return test_loss\n",
    "    \n",
    "    \n",
    "# Now use the train and test functions to train and test the model    \n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "print('Training on', device)\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = Net(num_classes=len(classes)).to(device)\n",
    "\n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 5 epochs (in a real scenario, you'd likely use many more)\n",
    "epochs = epochs\n",
    "\n",
    "if os.path.isfile(\"model.pt\"):\n",
    "    print(\"model.pt already exists and is now loaded, no training!\")\n",
    "    model = torch.load(\"model.pt\")\n",
    "else:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)\n",
    "    %matplotlib inline\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    plt.plot(epoch_nums, training_loss)\n",
    "    plt.plot(epoch_nums, validation_loss)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "    torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the training - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Set the model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions for the test data and convert to numpy arrays for use with SciKit-Learn\n",
    "print(\"Getting predictions from test set...\")\n",
    "truelabels = []\n",
    "predictions = []\n",
    "for data, target in test_loader:\n",
    "    for label in target.cpu().data.numpy():\n",
    "        truelabels.append(label)\n",
    "    for prediction in model.cpu()(data).data.numpy().argmax(1):\n",
    "        predictions.append(prediction) \n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Greys)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel(\"Predicted Shape\")\n",
    "plt.ylabel(\"True Shape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    import numpy\n",
    "    \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = transformation(image).float()\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all inputs as batches\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input_features = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    output = classifier(input_features)\n",
    "    index = output.data.numpy().argmax()\n",
    "    return index\n",
    "\n",
    "\n",
    "#Now let's try it with a new image\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import os, shutil\n",
    "    \n",
    "imgFile = Image.open(\"classify.jpg\")\n",
    "imgFile = imgFile.resize((resize_x,resize_y), Image.Resampling.LANCZOS)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(imgFile)\n",
    "\n",
    "# Call the predction function\n",
    "index = predict_image(model, imgFile)\n",
    "print(classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visit http://www.Terragon.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
