{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terragon.de Image Classifier (TIC-Torch)\n",
    "### with a PyTorch Convolutional Neural Network\n",
    "\n",
    "## Why TIC-Torch?\n",
    "\n",
    "The TIC-Torch workflow offers a convenient, fast and effective workflow to create, train and deploy individual and versatile image classifiers.\n",
    "\n",
    "## What's the workflow?\n",
    "\n",
    "1. Collect many jpg files of the objects you want to classify and arrange them in the \"raw\" directory. Create one subfolder for each object you want to classify and put the images inside. Example:\n",
    "    - raw/flowers\n",
    "    - raw/houses\n",
    "    - raw/sea\n",
    "3. Run TIC-Torch to resize and create variations of the images to train the Neural Network.\n",
    "4. Run TIC-Torch to classify a new jpg.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python libraries for OS, PyTorch and Image manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Libraries\n",
    "\n",
    "# Standard Python libraries for operating system and system-related functionalities.\n",
    "import os, sys \n",
    "# A function from distutils.dir_util to recursively copy directories.\n",
    "from distutils.dir_util import copy_tree \n",
    "# Classes and functions from the Python Imaging Library (PIL) for working with images and image processing.\n",
    "from PIL import Image, ImageEnhance \n",
    "import PIL.ImageOps\n",
    "# module for generating random numbers.\n",
    "import random \n",
    "\n",
    "# PyTorch Libraries\n",
    "# Core libraries of the PyTorch framework.\n",
    "import torch \n",
    "import torchvision\n",
    "# Module from torchvision for data transformations on images.\n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "# Modules from PyTorch for defining neural networks, optimization, autograd, and functional operations.\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# Other Libraries we'll use\n",
    "# A library for numerical computing in Python.\n",
    "import numpy as np \n",
    "# A library for creating visualizations and plots.\n",
    "import matplotlib.pyplot as plt \n",
    "# a magic command in Jupyter notebooks that ensures that plots are displayed within the notebook itself.\n",
    "%matplotlib inline \n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder where you put your source images\n",
    "path_images_raw = \"raw/\" \n",
    "# Path where this script will place the prepared images for training\n",
    "path_images_train = \"train/\" \n",
    "\n",
    "# we use 128 x 128 pixelssize for our training images\n",
    "resize_x = 128 \n",
    "resize_y = 128\n",
    "\n",
    "# so many images will be trained in one batch\n",
    "batch_size = 50 \n",
    "# training images will not be feeded one after the other, but it will shuffle the order randomly\n",
    "shuffle = True \n",
    "\n",
    "# how many epochs will be trained, An epoch is a complete pass through the entire training dataset\n",
    "epochs = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list subdirs in raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number and names of your subdirs is read from the raw directory, to prepare your classifications\n",
    "path_images_raw_subdirs = os.listdir(path_images_raw) \n",
    "print(\"raw/ subdirs: \",path_images_raw_subdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy all images from raw/ to train/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for raw and train are put into function\n",
    "def ImagesCopy(path_images_raw,path_images_train):\n",
    "    # copy all files from raw to train directory\n",
    "    copy_tree(path_images_raw, path_images_train) \n",
    "    # generate classes from subfolders in train directory (like above for raw directory)\n",
    "    path_images_train_subdirs = os.listdir(path_images_train) \n",
    "    print(\"copy from raw to train/ folder. done.\")\n",
    "    print(\"train subdirs: \",path_images_train_subdirs)\n",
    "# execute the above ImagesCopy() function\n",
    "ImagesCopy(path_images_raw,path_images_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resize all images in train/ to neural network size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImagesResize():\n",
    "    # loop for all images in train directory\n",
    "    for subdir, dirs, files in os.walk(path_images_train): \n",
    "        # sub-loop for all images in one subdirectory\n",
    "        for file in files: \n",
    "            # path to a single image\n",
    "            path_image = os.path.join(subdir, file) \n",
    "            # check if it is really a file\n",
    "            if os.path.isfile(path_image): \n",
    "                # open that image\n",
    "                im = Image.open(path_image) \n",
    "                # split the filename in filename f and extension e\n",
    "                f, e = os.path.splitext(path_image) \n",
    "                # resize image to resolution given above (128x128)\n",
    "                imResize = im.resize((resize_x,resize_y), Image.Resampling.LANCZOS) \n",
    "                # save resized image as file with the name f + \"_resized.jpg\"\n",
    "                imResize.save(f + '_resized.jpg', 'JPEG', quality=90) \n",
    "                # delete original image from train folder (it remains in raw folder)\n",
    "                os.remove(path_image) \n",
    "    print(\"resized all images in folder train/\")\n",
    "# execute the above ImagesResize() function\n",
    "ImagesResize() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create variations of all images in train/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageVariations():\n",
    "    # loop for all images in train directory\n",
    "    for subdir, dirs, files in os.walk(path_images_train): \n",
    "        # sub-loop for all images in one subdirectory\n",
    "        for file in files: \n",
    "            # path to a single image\n",
    "            path_image = os.path.join(subdir, file) \n",
    "            # check if it is really a file\n",
    "            if os.path.isfile(path_image): \n",
    "                # open that image\n",
    "                im = Image.open(path_image) \n",
    "                # split the filename in filename f and extension e\n",
    "                f, e = os.path.splitext(path_image) \n",
    "                # Make image lighter\n",
    "                enhancer = ImageEnhance.Brightness(im)\n",
    "                imLighter = enhancer.enhance(1.8)\n",
    "                # save resized image as file with the name f + \"_lighter.jpg\"\n",
    "                imLighter.save(f + '_lighter.jpg', 'JPEG', quality=90) \n",
    "                # make image darker\n",
    "                imDarker = enhancer.enhance(0.5)\n",
    "                imDarker.save(f + '_darker.jpg', 'JPEG', quality=90)\n",
    "                # invert image\n",
    "                imInverted = PIL.ImageOps.invert(im)\n",
    "                imInverted.save(f + '_inverted.jpg', 'JPEG', quality=90)\n",
    "                # rotate n random degree between -45 and +45 degree\n",
    "                randomRotate = random.randrange(-45,45)\n",
    "                imRotated = im.rotate(randomRotate)\n",
    "                imRotated.save(f + '_rotated.jpg', 'JPEG', quality=90)\n",
    "                # mirror image\n",
    "                imMirror = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                imMirror.save(f + '_mirrored.jpg', 'JPEG', quality=90)\n",
    "                # make image grayscale\n",
    "                imGrey = im.convert('L')\n",
    "                imGrey.save(f + '_greyscale.jpg', 'JPEG', quality=90)\n",
    "    print(\"added a mirror and greyscale images for all images in folder train/\")\n",
    "# execute the above ImageVariations() function\n",
    "ImageVariations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer all Images to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ingest data using training and test loaders\n",
    "# Now load the images from the train folder\n",
    "\n",
    "def load_dataset(path_images_train): # path to te train directory with all the image variations\n",
    "    # Load all of the images\n",
    "    # this will be used with torchvision, Composes several transforms together, https://pytorch.org/vision/main/generated/torchvision.transforms.Compose.html\n",
    "    transformation = transforms.Compose([ \n",
    "        # transform imagefile to tensors\n",
    "        transforms.ToTensor(), \n",
    "        # Normalize the pixel values (in R, G, and B channels) , \n",
    "        # Normalize a tensor image with mean and standard deviation, https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder( \n",
    "            # use torchvision \"ImageFolder\"\n",
    "            #A generic data loader where the images are arranged in this way by default:\n",
    "            #root/dog/xxx.png\n",
    "            #root/dog/xxy.png\n",
    "            #root/dog/[...]/xxz.png\n",
    "\n",
    "            #root/cat/123.png\n",
    "            #root/cat/nsdf3.png\n",
    "            #root/cat/[...]/asd932_.png\n",
    "        root=path_images_train,       # give the path to train folder\n",
    "        transform=transformation      # apply the \"transformation\" function above, for every image\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))      # take the length of \"full_dataset\" from above and take 0.7 = 70% as a int\n",
    "    test_size = len(full_dataset) - train_size     # take len of \"full_dataset\" - the int of train_size\n",
    "    # now divide the \"full_dataset\" with the two ints in \"train_dataset\" and \"test_dataset\" in random order\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size]) \n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader( # At the heart of PyTorch data loading utility is the torch.utils.data.DataLoader class. \n",
    "                                                # It represents a Python iterable over a dataset, with support for\n",
    "                                                # map-style and iterable-style datasets,\n",
    "                                                # customizing data loading order,\n",
    "                                                # automatic batching,\n",
    "                                                # single- and multi-process data loading,\n",
    "                                                # automatic memory pinning.\n",
    "                                        #DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "                                           #batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "                                           #pin_memory=False, drop_last=False, timeout=0,\n",
    "                                           #worker_init_fn=None, *, prefetch_factor=2,\n",
    "                                           # persistent_workers=False)\n",
    "        train_dataset,               # from above\n",
    "        batch_size=batch_size,       # from above\n",
    "        num_workers=0,               # Num_workers tells the data loader instance how many sub-processes to use for data loading. \n",
    "                                     # If the num_worker is zero (default) the GPU has to weight for CPU to load data\n",
    "        shuffle=shuffle              # here we shuffle the order of training images again \n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data (like \"train_loader\" before)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader    # returns the \"train_loader\" and \"test_loader\"\n",
    "\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(path_images_train)      # imports all the folder names in the train folder and puts them into classes\n",
    "classes.sort()                               # sorts the classes by name\n",
    "classes_amount = len(classes)                # count the classes\n",
    "print(len(classes), 'classes are found in your train folder:')\n",
    "print(classes)\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "# starts the load_dataset() function from above\n",
    "train_loader, test_loader = load_dataset(path_images_train)          \n",
    "\n",
    "# Show the shape and content of the train_loader\n",
    "print(\"Shape of the train_loader and test_loader (images per batch, RGB channels, width, height):\")\n",
    "for epoch in range(1):                            # range is the number of epochs that will be shown, for example 1 epoch\n",
    "    for i, data in enumerate(train_loader, 0):    # enumerate() is a built-in function that allows you to iterate over a sequence (train_loader)\n",
    "                                                  # (like a list, tuple, or iterator) while keeping track of both the index and the element in the sequence. \n",
    "                                                  # The second argument you provide to enumerate() is a starting value for the index.\n",
    "                                                  # train_loader is enumerated into \"data\"\n",
    "        # get the inputs\n",
    "        inputs, labels = data                     # data is split into inputs (image data) and labels (classes)\n",
    "        inputs = np.array(inputs)                 # inputs (image data) is converted to numpy array\n",
    "        print(inputs.shape)                       # show shape of inputs\n",
    "        # simulate the training process\n",
    "        # print(f'Epoch: {i} | Inputs {inputs} | Labels {labels}')      # prints the content of all tensors (many numbers...)\n",
    "                                                                        # In the end there is also a \"Labels tensor\", with the classes\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural net class\n",
    "# When you define a class that inherits from nn.Module, you are creating a custom neural network architecture. \n",
    "# This class allows you to define the structure of your neural network, including its layers and operations.\n",
    "class Net(nn.Module): \n",
    "    # Constructor\n",
    "    def __init__(self, num_classes=classes_amount):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Our images are RGB, so input channels = 3. wW'll apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # self.conv1: creating an instance variable named conv1 within the class instance. \n",
    "        # The self keyword refers to the instance of the class you are defining, and this line of code is creating a convolutional layer and \n",
    "        # assigning it to this instance variable.\n",
    "        # nn.Conv2d: This is the class in PyTorch's nn (neural network) module that represents a 2-dimensional convolutional layer.\n",
    "        # in_channels=3: specifies the number of input channels for the convolutional layer. \n",
    "        # 3 for RGB color images where each channel represents red, green, and blue.\n",
    "        # out_channels=12: the layer will produce 12 different feature maps as output.\n",
    "        # kernel_size=3: size of the convolutional kernel (filter) that will slide over the input data. In this case, it's a 3x3 kernel.\n",
    "        # stride=1: the stride of the convolution operation. A stride of 1 means that the kernel moves one pixel at a time.\n",
    "        # padding=1: This specifies the amount of zero-padding to be added to the input data before applying the convolution. \n",
    "        # Padding helps control the spatial dimensions of the output. A padding of 1 means that a border of one pixel of zeros will be added around the input.\n",
    "        \n",
    "        # We'll apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # self.pool: This is creating an instance variable named pool within the class instance. \n",
    "        # The self keyword refers to the instance of the class you are defining, and this line of code is creating a \n",
    "        # max pooling layer and assigning it to this instance variable.\n",
    "        # nn.MaxPool2d: This is the class in PyTorch's nn (neural network) module that represents a 2-dimensional max pooling layer.\n",
    "        # kernel_size=2: This specifies the size of the pooling window. In this case, it's a 2x2 window. Max pooling takes the \n",
    "        # maximum value from the elements within the window.\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 12 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # stride=1: This specifies the stride of the convolution operation. \n",
    "        # It determines the step size at which the kernel moves over the input data. \n",
    "        # A stride of 1 means that the kernel moves one pixel at a time.\n",
    "        # padding=1: This specifies the amount of zero-padding to be added to the input data before applying the convolution. \n",
    "        # Padding helps control the spatial dimensions of the output. \n",
    "        # A padding of 1 means that a border of one pixel of zeros will be added around the input.\n",
    "        \n",
    "        # A third convolutional layer takes 12 inputs and generates 24 outputs\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "\n",
    "        # nn.Dropout2d: This is the class in PyTorch's nn (neural network) module that represents a 2D dropout layer. \n",
    "        # Dropout is a regularization technique used during training to prevent overfitting by \n",
    "        # randomly \"dropping out\" (setting to zero) a fraction of the input units.\n",
    "        # p=0.2: This specifies the probability of dropping out a unit. In this case, it's set to 0.2, \n",
    "        # meaning that during training, each element in the input tensor will have a 20% chance of being set to zero.\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # So our feature tensors are now 32 x 32, and we've generated 24 of them\n",
    "        # We need to flatten these to map them to  the probability for each class\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
    "\n",
    "        #in_features=32 * 32 * 24: This specifies the number of input features (neurons) to the fully connected layer. \n",
    "        # The value 32 * 32 * 24 represents the flattened size of the input feature map. It appears to be assuming a 32x32 feature map with 24 channels.\n",
    "        # out_features=num_classes: This specifies the number of output features (neurons) from the fully connected layer. \n",
    "        # In the context of classification, this typically corresponds to the number of classes in your classification problem. \n",
    "        # The variable num_classes should be defined earlier in your code to indicate the number of classes.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use a relu activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        # Use a relu activation function after layer 1 (convolution 2 and drop)\n",
    "\n",
    "        # self.conv1(x): This applies the first convolutional layer (conv1) to the input tensor x. \n",
    "        # It convolves the input tensor with the learnable filters of the convolutional layer, extracting features from the input. \n",
    "        # The output of this operation will be a tensor containing the feature maps produced by the convolution.\n",
    "        # self.pool(...): This applies a pooling operation to the tensor. In this case, self.pool likely refers to a \n",
    "        # max pooling layer (MaxPool2d) that was defined earlier in the neural network architecture. \n",
    "        # Pooling helps downsample the feature maps while retaining important information. \n",
    "        # It's common to use pooling to reduce the spatial dimensions of the data and control the number of parameters in the network.\n",
    "        # F.relu(...): This applies the Rectified Linear Unit (ReLU) activation function to the tensor. \n",
    "        # ReLU is a non-linear activation function that replaces negative values with zero while leaving positive values unchanged.\n",
    "        # It introduces non-linearity into the network and helps the network learn complex relationships in the data.\n",
    "        \n",
    "        # Use a relu activation function after layer 3 (convolution 3)\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        \n",
    "        # Drop some features after the 3rd convolution to prevent overfitting\n",
    "        x = F.relu(self.drop(self.conv3(x)))\n",
    "        # Only drop the features if this is a training pass\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # x = F.relu(self.drop(self.conv3(x))):\n",
    "        # self.conv3(x): Applies the third convolutional layer (conv3) to the input tensor x.\n",
    "        # self.drop(...): Applies dropout to the tensor. self.drop likely refers to a dropout layer (Dropout2d) defined earlier in the network.\n",
    "        # F.relu(...): Applies the ReLU activation function to the tensor, introducing non-linearity.\n",
    "        # So, this line first applies a convolutional layer, then dropout, and finally the ReLU activation function to the feature maps in sequence.\n",
    "\n",
    "        # x = F.dropout(x, training=self.training):\n",
    "        # F.dropout(...): Applies dropout using the F.dropout function from the torch.nn.functional module. \n",
    "        # This function is used to apply dropout to the input tensor x.\n",
    "        # x: The tensor on which the dropout is being applied.\n",
    "        # training=self.training: The self.training attribute is a boolean value that indicates whether the model \n",
    "        # is in training mode or evaluation mode. Dropout is only applied during training, not during evaluation or inference.\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # x = x.view(-1, 32 * 32 * 24):\n",
    "        # x: The input tensor, likely containing the feature maps from the previous layers.\n",
    "        # .view(...): This method reshapes the tensor. The -1 argument indicates that the size of that dimension \n",
    "        # should be inferred to maintain the total number of elements in the tensor. \n",
    "        # The second argument 32 * 32 * 24 specifies the desired size of the other dimension, which corresponds to the flattened size of the feature maps.\n",
    "        # This line is reshaping the tensor x from its current shape to a 2D tensor where each row represents a flattened feature map.\n",
    "\n",
    "        # x = self.fc(x):\n",
    "        # self.fc: A fully connected (fc, dense) layer defined earlier in the network.\n",
    "        # x: The reshaped tensor from the previous line.\n",
    "        # This line applies the fully connected layer (fc) to the reshaped tensor x. \n",
    "        # The fully connected layer performs a linear transformation on the input data and produces an output tensor suitable for classification.\n",
    "\n",
    "        # Return class probabilities via a softmax function \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "        # F.log_softmax(...): computes the log of the softmax of the input tensor along a specified dimension. \n",
    "        # it produces normalized log probabilities for each class.\n",
    "        # x: The input tensor to which the log softmax function is applied. \n",
    "        # This is typically the output of the fully connected layer or the final layer of your neural network.\n",
    "        # dim=1: This specifies the dimension along which the log softmax operation is performed. \n",
    "        # In most cases, this is set to 1, which corresponds to the class dimension in a classification problem.\n",
    "    \n",
    "print(\"CNN model class defined!\")\n",
    "\n",
    "net = Net() # create a net copy to print the structure\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # model: The neural network model that will be trained.\n",
    "    # device: The device (CPU or GPU) on which the training will be performed.\n",
    "    # train_loader: A data loader that provides batches of training data.\n",
    "    # optimizer: The optimization algorithm used for updating the model's parameters.\n",
    "    # epoch: The current epoch number.\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train() # Sets the model in training mode. This is necessary to activate certain behaviors like dropout and batch normalization during training.\n",
    "    train_loss = 0 # Initializes the running total of the training loss and prints the current epoch number.\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    #This loop iterates through batches of training data, where each batch consists of data (input images) and their corresponding target labels.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        # Transfers both the input data and target labels to the specified device (CPU or GPU).\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Reset the optimizer, Resets the gradients of the model's parameters. This is necessary before performing backpropagation.\n",
    "        optimizer.zero_grad()\n",
    "        # Push the data forward through the model layers, Passes the input data through the model's layers to obtain the predicted output.\n",
    "        output = model(data)\n",
    "        # Get the loss, Computes the loss between the predicted output and the actual target labels.\n",
    "        loss = loss_criteria(output, target)\n",
    "        # Keep a running total, Accumulates the loss for the current batch to the running total.\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward() # Computes gradients of the loss with respect to the model's parameters using backpropagation.\n",
    "        optimizer.step() # Updates the model's parameters using the computed gradients.\n",
    "        # Print metrics for every 10 batches so we see some progress, showing the batch number, total number of batches, \n",
    "        # progress percentage, and the current batch's loss.\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    # return average loss for the epoch\n",
    "    #Returns the average loss for the entire epoch, calculated by dividing the accumulated loss by the total number of training samples.\n",
    "    return train_loss / len(train_loader.dataset) \n",
    "            \n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop), \n",
    "    # This disables certain behaviors like dropout and batch normalization, ensuring consistent evaluation results.\n",
    "    model.eval()\n",
    "    test_loss = 0    # Initializes the running total of the test loss and the count of correct predictions.\n",
    "    correct = 0\n",
    "    # This loop iterates through batches of testing data, where each batch consists of data (input images) and their corresponding target labels.\n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:                               # disables gradient computation, reducing memory usage and speeding up inference.\n",
    "            data, target = data.to(device), target.to(device)          # Transfers both the input data and target labels to the specified device (CPU or GPU).\n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)                                       # Passes the input data through the model's layers to obtain the predicted output.\n",
    "            # calculate the loss and successful predictions for this batch\n",
    "            test_loss += loss_criteria(output, target).item()          # Accumulates the loss for the current batch to the running total.\n",
    "            pred = output.max(1, keepdim=True)[1]                      # Predicted class labels obtained by finding the maximum value along dimension 1 of the output tensor.\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()      # Counts the number of correct predictions in the current batch.\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    test_loss /= len(test_loader.dataset) # Calculates the average test loss by dividing the accumulated loss by the total number of testing samples.\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset))) # Prints the average loss and accuracy percentage for the testing set.\n",
    "    \n",
    "    # return average loss for the epoch, useful for monitoring the model's performance over time.\n",
    "    return test_loss\n",
    "    \n",
    "    \n",
    "# Now use the train and test functions to train and test the model    \n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "print('Training on', device)\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "# creates an instance of the neural network model based on the Net class, sets the number of output classes based on the length of the classes list\n",
    "model = Net(num_classes=len(classes)).to(device) \n",
    "\n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# The learning rate controls the step size at each iteration during optimization. A smaller learning rate may lead to slower convergence \n",
    "# but more stable optimization, \n",
    "# while a larger learning rate may lead to faster convergence but could result in overshooting the optimal solution.\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "# Cross-entropy loss is used for training classification models where each input sample belongs to one of multiple classes. \n",
    "# It combines both the softmax activation and the negative log likelihood loss into a single operation.\n",
    "\n",
    "# Track metrics in these arrays\n",
    "# By recording these loss values for each epoch, you can visualize how the model's performance improves over time \n",
    "# and detect any potential overfitting or convergence issues\n",
    "epoch_nums = [] # store the epoch numbers during training\n",
    "training_loss = [] \n",
    "validation_loss = [] # The validation loss provides an indication of how well the model generalizes to new, unseen data\n",
    "\n",
    "# Train over the number of epochs defined above\n",
    "epochs = epochs\n",
    "\n",
    "# check if you already have a trained model, if yes, no training will happen, instead the saved model will be loaded \n",
    "if os.path.isfile(\"model.pt\"):\n",
    "    print(\"model.pt already exists and is now loaded, no training!\")\n",
    "    model = torch.load(\"model.pt\")\n",
    "else:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # This loop iterates over the specified number of epochs. For each epoch, it performs the training by calling the \n",
    "        # train function and calculates the training loss. It also evaluates the model on the validation dataset using the \n",
    "        # test function and calculates the validation loss. The epoch number, training loss, and validation loss are then appended to the respective arrays.\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)\n",
    "    %matplotlib inline\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    # This code block uses Matplotlib to plot the training and validation loss curves over the epochs. \n",
    "    # It sets the X-axis as the epoch numbers and the Y-axis as the loss values. It then displays the plot with labeled axes and a legend.\n",
    "    plt.plot(epoch_nums, training_loss)\n",
    "    plt.plot(epoch_nums, validation_loss)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    # After the training loop, the script saves the trained model to a file named \"model.pt\" using the torch.save function. \n",
    "    # This allows you to load the trained model later for inference or further training without starting from scratch.\n",
    "    torch.save(model, \"model.pt\")\n",
    "    # Delete previous model.pt file if you want to train new!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the training - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Set the model to evaluate mode\n",
    "# ensures that dropout and batch normalization layers behave appropriately for inference. \n",
    "# Remember to call model.train() to switch the model back to training mode when you resume training\n",
    "model.eval()\n",
    "\n",
    "# Get predictions for the test data and convert to numpy arrays for use with SciKit-Learn\n",
    "print(\"Getting predictions from test set...\")\n",
    "truelabels = [] # two lists that will store the true labels \n",
    "predictions = [] # two lists that will store the model's predicted labels, respectively.\n",
    "for data, target in test_loader: # loops over the batches of data and target labels provided by the test_loader.\n",
    "    for label in target.cpu().data.numpy():\n",
    "        # In the first loop, it iterates through the true labels (target) in the current batch. \n",
    "        # The target tensor is converted to a NumPy array using .cpu().data.numpy(), \n",
    "        # which extracts the data from the tensor on the CPU and converts it to a NumPy array. Each true label is then appended to the truelabels list.\n",
    "        truelabels.append(label)\n",
    "    for prediction in model.cpu()(data).data.numpy().argmax(1):\n",
    "        # In the second loop, it iterates through the data (data) in the current batch. \n",
    "        # It passes the data through the model for prediction. model.cpu() moves the model to the CPU (if it was on the GPU), \n",
    "        # and (data) applies the data to the model\n",
    "        #  .data.numpy().argmax(1) converts the model's output tensor to a NumPy array and selects the index with the highest value along dimension 1, \n",
    "        # which corresponds to the predicted class label. Each predicted label is then appended to the predictions list.\n",
    "        predictions.append(prediction) \n",
    "\n",
    "# Plot the confusion matrix, create and display a confusion matrix using the confusion_matrix function from scikit-learn, \n",
    "# along with some visualization using matplotlib\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "# the confusion_matrix function from scikit-learn is used to compute the confusion matrix. It takes two arguments: \n",
    "# truelabels (the true labels of the samples) and predictions (the predicted labels by the model). \n",
    "# The resulting cm is a 2D array where each element (i, j) represents the number of samples that belong to class i and were predicted to be in class j.\n",
    "# The interpolation=\"nearest\" argument ensures that the cells are shown with sharp boundaries. \n",
    "# cmap=plt.cm.Greys specifies the colormap to use for visualization (in this case, a grayscale colormap).\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Greys) \n",
    "plt.colorbar() # serves as a visual guide for the color mapping of the confusion matrix values\n",
    "# tick_marks is an array containing the indices of the classes. It's used to position the ticks on the x and y axes of the plot.\n",
    "tick_marks = np.arange(len(classes)) \n",
    "# set the tick marks on the x-axis using the class names (stored in classes) and rotates them by 45 degrees for better readability.\n",
    "plt.xticks(tick_marks, classes, rotation=45) \n",
    "plt.yticks(tick_marks, classes) # sets the tick marks on the y-axis using the class names\n",
    "plt.xlabel(\"Predicted Shape\")\n",
    "plt.ylabel(\"True Shape\") # set the labels for the x and y axes of the plot to describe the meaning of each axis\n",
    "plt.show() # displays the complete plot with the confusion matrix and the associated visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    # takes a classifier model and an image as inputs and returns the predicted class index for the given image\n",
    "    import numpy\n",
    "    \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval() # Puts the classifier model into evaluation mode\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([ # converts the image to a tensor and applies normalization\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    # make sure that the classifier model and the image are compatible in terms of input size and data type\n",
    "    image_tensor = transformation(image).float() # uses transformation above to the image\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all inputs as batches\n",
    "    # The preprocessed image tensor is expanded along a new batch dimension using unsqueeze_(0) to match the batch format expected by the model\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    # The input tensor is wrapped in a PyTorch Variable using Variable(image_tensor).\n",
    "    input_features = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    # The model is used to predict the class of the image by passing the input tensor through the classifier model using classifier(input_features).\n",
    "    output = classifier(input_features)\n",
    "    index = output.data.numpy().argmax() \n",
    "    # The output tensor is converted to a NumPy array using .data.numpy()\n",
    "    # The index of the class with the highest score is extracted using .argmax().\n",
    "    return index\n",
    "\n",
    "\n",
    "#Now let's try it with a new image\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import os, shutil\n",
    "    \n",
    "imgFile = Image.open(\"test.jpg\") # opens the image you want to classify\n",
    "imgFile = imgFile.resize((resize_x,resize_y), Image.Resampling.LANCZOS) # resizes to the models size given above\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(imgFile) # show the image\n",
    "\n",
    "# Call the predction function\n",
    "index = predict_image(model, imgFile) # use model from above and imgFile just opened\n",
    "print(classes[index]) # prints the class that had highest score in argmax above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visit http://www.Terragon.de\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
